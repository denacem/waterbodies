{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project work: A mini segmentation challenge\n",
    "\n",
    "Imaging for the Life Sciences  \n",
    "MSLS / CO4: Project work\n",
    "\n",
    "**Student**: $\\Rightarrow$ Mirco Blaser\n",
    "\n",
    "**University**: $\\Rightarrow$ ZHAW\n",
    "\n",
    "**Semester**: $\\Rightarrow$ 4th Semester\n",
    "\n",
    "**Date**: $\\Rightarrow$ June 3rd 2024\n",
    "\n",
    "**Github repository**: $\\Rightarrow$ https://github.com/denacem/waterbodies\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "<!-- Unfortunately, the following does not always work correctly -->\n",
    "* [1. Dataset](#sec_dataset)  \n",
    "* [2. Preprocessing](#sec_preprocessing)  \n",
    "* [3. Manual segmentation](#sec_manual_segmentation)  \n",
    "* [4. Automated segmentation](#sec_automated_segmentation)  \n",
    "* [5. Evaluation](#sec_evaluation)  \n",
    "* [6. Discussion](#sec_discussion)\n",
    "* [7. References](#sec_references)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prerequisites / Setup\n",
    "\n",
    "$\\Rightarrow$  Special setup instructions, imports and configurations go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Smaller Matplotlib titles for PDF print\n",
    "plt.rcParams['axes.titlesize'] = 'medium'\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "# Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable this line if you want to use the interactive widgets\n",
    "# It requires the ipympl package to be installed.\n",
    "#%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import tools\n",
    "\n",
    "# Number of samples to create for the whole code\n",
    "num_samples = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_dataset'></a>\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Title: Satellite Images of Water Bodies\n",
    "\n",
    "Source: [Kaggle](https://www.kaggle.com/datasets/franciscoescobar/satellite-images-of-water-bodies)\n",
    "\n",
    "Description: A collection of water bodies images captured by the Sentinel-2 Satellite. Each image comes with a black and white mask where white represents water and black represents something else but water. The masks were generated by calculating the NWDI (Normalized Water Difference Index) which is frequently used to detect and measure vegetation in satellite images, but a greater threshold was used to detect water bodies.\n",
    "\n",
    "- **Images**: These are the raw satellite images.\n",
    "- **Masks**: These are the binary masks where water bodies are labeled.\n",
    "\n",
    "Below are examples of the images and their corresponding masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the directories containing images and masks\n",
    "images_path = './data/Images'\n",
    "masks_path = './data/Masks'\n",
    "\n",
    "# Function to load images and masks\n",
    "def load_images_masks(image_dir, mask_dir, num_samples=None, batch_size=100):\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "    \n",
    "    num_samples = num_samples or len(image_files)\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        image_batch_files = image_files[i:i+batch_size]\n",
    "        mask_batch_files = mask_files[i:i+batch_size]\n",
    "        \n",
    "        image_batch = []\n",
    "        mask_batch = []\n",
    "        \n",
    "        for image_file, mask_file in zip(image_batch_files, mask_batch_files):\n",
    "            with Image.open(os.path.join(image_dir, image_file)) as image:\n",
    "                image_batch.append(image.copy())\n",
    "                \n",
    "            with Image.open(os.path.join(mask_dir, mask_file)) as mask:\n",
    "                mask_batch.append(mask.copy())\n",
    "                \n",
    "        images.extend(image_batch)\n",
    "        masks.extend(mask_batch)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "# Load the first num_samples images and masks\n",
    "images, masks = load_images_masks(images_path, masks_path, num_samples)\n",
    "\n",
    "# Display the images and masks\n",
    "fig, axs = plt.subplots(num_samples, 2, figsize=(5, num_samples*2.5))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axs[i, 0].imshow(images[i])\n",
    "    axs[i, 0].set_title(f'Image {i+1}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Mask {i+1}')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_preprocessing'></a>\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "1. **Resizing**: Standardized the image sizes to 256x256 pixels.\n",
    "2. **Normalization**: Adjusted the pixel values to the range [0, 1].\n",
    "3. **Contrast Enhancement**: Applied histogram equalization to enhance the contrast of the images.\n",
    "\n",
    "Below are the examples of the preprocessed images and their corresponding masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image, ismask):\n",
    "    target_width = 256\n",
    "    \n",
    "    # Check if the image has valid dimensions\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Calculate the target height to maintain the original aspect ratio\n",
    "    target_height = int(height * (target_width / width))\n",
    "    \n",
    "    # Fix because some crazy distorted images get a height of 0 and mess things up\n",
    "    if target_height == 0:\n",
    "        target_height = 1\n",
    "    \n",
    "    # Resize the image while maintaining aspect ratio\n",
    "    image_resized = image.resize((target_width, target_height), PIL.Image.LANCZOS)\n",
    "    \n",
    "    if not ismask:\n",
    "        \n",
    "        # Convert the image to a numpy array and then to grayscale directly\n",
    "        image_array = np.array(image_resized)\n",
    "        image_grayscale = cv.cvtColor(image_array, cv.COLOR_BGR2GRAY)\n",
    "        image_enhanced = image_grayscale\n",
    "    else:\n",
    "        image_enhanced = np.array(image_resized.convert('L'))\n",
    "    \n",
    "    return image_enhanced\n",
    "\n",
    "# Preprocess the first num_samples images and masks\n",
    "preprocessed_images = [preprocess_image(images[i], ismask=False) for i in range(num_samples)]\n",
    "preprocessed_masks = [preprocess_image(masks[i], ismask=True) for i in range(num_samples)]\n",
    "\n",
    "# Display the preprocessed images and masks\n",
    "fig, axs = plt.subplots(num_samples, 2, figsize=(5, num_samples*2.5))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axs[i, 0].imshow(preprocessed_images[i], cmap='gray')\n",
    "    axs[i, 0].set_title(f'Preprocessed Image {i+1}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(preprocessed_masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Preprocessed Mask {i+1}')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='sec_manual_segmentation'></a>\n",
    "\n",
    "## Manual segmentation\n",
    "\n",
    "For the manual segmentation, the Fiji (ImageJ) software was used. Fiji is an open-source image processing package that is widely used in the life sciences for its powerful and user-friendly tools.\n",
    "\n",
    "### Steps for Manual Segmentation in Fiji:\n",
    "\n",
    "1. **Open Image**: Load the image into Fiji by going to `File > Open...` and selecting the image file.\n",
    "2. **Select the Region of Interest**: Use the Polygon selection tool to carefully outline the water body in the image.\n",
    "3. **Create a Mask**: Once the water body is selected, go to Edit > Selection > Create Mask. This creates a binary mask where the selected region is white, and the rest is black.\n",
    "5. **Save Mask**: Save the resulting mask by going to `File > Save As > PNG...`.\n",
    "\n",
    "The following code displays the original images, the original masks, and the manually segmented masks for the selected images (100, 170, and 708)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the directories containing images and masks\n",
    "images_path = './data/Images/'\n",
    "masks_path = './data/Masks/'\n",
    "manual_masks_path = './manual/'\n",
    "\n",
    "# List of specific image indices to load\n",
    "image_indices = [100, 170, 708]\n",
    "\n",
    "# Function to load specific images and masks\n",
    "def load_specific_images_masks(image_dir, mask_dir, manual_mask_dir, indices):\n",
    "    images = []\n",
    "    masks = []\n",
    "    manual_masks = []\n",
    "    for index in indices:\n",
    "        image_file = f'water_body_{index}.jpg'\n",
    "        mask_file = f'water_body_{index}.jpg'\n",
    "        manual_mask_file = f'water_body_{index}.png'\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        manual_mask_path = os.path.join(manual_mask_dir, manual_mask_file)\n",
    "        images.append(Image.open(image_path))\n",
    "        masks.append(Image.open(mask_path))\n",
    "        manual_masks.append(Image.open(manual_mask_path))\n",
    "    \n",
    "    return images, masks, manual_masks\n",
    "\n",
    "# Load the specific images and masks\n",
    "images, masks, manual_masks = load_specific_images_masks(images_path, masks_path, manual_masks_path, image_indices)\n",
    "\n",
    "# Display the images and masks\n",
    "fig, axs = plt.subplots(len(images), 3, figsize=(5, 2 * len(images)))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    axs[i, 0].imshow(images[i])\n",
    "    axs[i, 0].set_title(f'Image {image_indices[i]}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Original Mask {image_indices[i]}')\n",
    "    axs[i, 1].axis('off')\n",
    "    \n",
    "    axs[i, 2].imshow(manual_masks[i], cmap='gray')\n",
    "    axs[i, 2].set_title(f'Manual  Mask {image_indices[i]}')\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_automated_segmentation'></a>\n",
    "\n",
    "## Automated segmentation\n",
    "\n",
    "For the automated segmentation I created a segment() function that takes an image and a method and creates a segmented mask with the CV library. For watershed a separate function is created.\n",
    "\n",
    "The function is called for the number of samples and run for all the four methods. Finally the results are visualised next to the original images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the segmentation function\n",
    "def segment(image, method='global'):\n",
    "    \n",
    "    # Check the number of channels in the image\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        # Convert the image to grayscale if it has 3 channels\n",
    "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        # Image is already in grayscale\n",
    "        gray = image\n",
    "    \n",
    "    if method == 'global':\n",
    "        # Apply global thresholding\n",
    "        _, mask = cv.threshold(gray, 127, 255, cv.THRESH_BINARY)\n",
    "    elif method == 'adaptive':\n",
    "        # Apply adaptive thresholding\n",
    "        mask = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
    "    elif method == 'otsu':\n",
    "        # Apply Otsu's thresholding\n",
    "        _, mask = cv.threshold(gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    elif method == 'watershed':\n",
    "        # Apply watershed segmentation\n",
    "        markers, img = segment_watershed(image)\n",
    "        # Create a binary mask where the segmented regions are white\n",
    "        mask = np.zeros_like(gray)\n",
    "        mask[markers > 1] = 255  # We assume the labels greater than 1 correspond to foreground regions\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def segment_watershed(img):\n",
    "    img = cv.GaussianBlur(img, (5, 5), 0)\n",
    "    img_blur = cv.medianBlur(img, 5)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    if len(img_blur.shape) == 3 and img_blur.shape[2] == 3:\n",
    "        gray = cv.cvtColor(img_blur, cv.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img_blur\n",
    "    \n",
    "    ret, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "    # Noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=9)\n",
    "\n",
    "    # Sure background area\n",
    "    sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
    "    thr = 18\n",
    "    ret, sure_fg = cv.threshold(dist_transform, thr, 255, 0)\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    # Ensure the image is in color\n",
    "    if len(img.shape) == 2 or img.shape[2] != 3:\n",
    "        img = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    markers = cv.watershed(img, markers)\n",
    "    img[markers == -1] = [255, 0, 0]\n",
    "\n",
    "    return markers, img\n",
    "\n",
    "# Segment the preprocessed images using different methods\n",
    "segmented_masks_otsu = [segment(image, method='otsu') for image in preprocessed_images]\n",
    "segmented_masks_adaptive = [segment(image, method='adaptive') for image in preprocessed_images]\n",
    "segmented_masks_global = [segment(image, method='global') for image in preprocessed_images]\n",
    "segmented_masks_watershed = [segment(image, method='watershed') for image in preprocessed_images]\n",
    "\n",
    "# Display the results\n",
    "fig, axs = plt.subplots(num_samples, 6, figsize=(10, num_samples * 2))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axs[i, 0].imshow(preprocessed_images[i], cmap='gray')\n",
    "    axs[i, 0].set_title(f'Preprocessed Image {i+1}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(preprocessed_masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Preprocessed Mask {i+1}')\n",
    "    axs[i, 1].axis('off')\n",
    "    \n",
    "    axs[i, 2].imshow(segmented_masks_global[i], cmap='gray')\n",
    "    axs[i, 2].set_title(f'Global Threshold {i+1}')\n",
    "    axs[i, 2].axis('off')\n",
    "    \n",
    "    axs[i, 3].imshow(segmented_masks_adaptive[i], cmap='gray')\n",
    "    axs[i, 3].set_title(f'Adaptive Threshold {i+1}')\n",
    "    axs[i, 3].axis('off')\n",
    "    \n",
    "    axs[i, 4].imshow(segmented_masks_otsu[i], cmap='gray')\n",
    "    axs[i, 4].set_title(f'Otsu Threshold {i+1}')\n",
    "    axs[i, 4].axis('off')\n",
    "    \n",
    "    axs[i, 5].imshow(segmented_masks_watershed[i], cmap='gray')\n",
    "    axs[i, 5].set_title(f'Watershed {i+1}')\n",
    "    axs[i, 5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_evaluation'></a>\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "For the evaluation, first of all the segmented masks for a larger set is images is created.\n",
    "\n",
    "The dice() function from the module repository is used to calculate the dice coefficients. The function is called for every mask, creating a dictionary with all the coefficients. Finally the mean and standard deviations for every method is calculated and visualised in an error bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the segmentation for the whole dataset now, without visualizing the result\n",
    "\n",
    "# Load the images and masks\n",
    "# Only 200 works for now\n",
    "images, masks = load_images_masks(images_path, masks_path, 200)\n",
    "\n",
    "# Preprocess images and masks\n",
    "preprocessed_images = [preprocess_image(image, ismask=False) for image in images]\n",
    "preprocessed_masks = [preprocess_image(mask, ismask=True) for mask in masks]\n",
    "\n",
    "# # Segment the preprocessed images using different methods\n",
    "segmented_masks_otsu = [segment(image, method='otsu') for image in preprocessed_images]\n",
    "segmented_masks_adaptive = [segment(image, method='adaptive') for image in preprocessed_images]\n",
    "segmented_masks_global = [segment(image, method='global') for image in preprocessed_images]\n",
    "segmented_masks_watershed = [segment(image, method='watershed') for image in preprocessed_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to compute the Dice coefficient\n",
    "def dice(mask1, mask2):\n",
    "    \"\"\"Compute the Dice coefficient. The input masks should be binary.\"\"\"\n",
    "    assert mask1.shape == mask2.shape\n",
    "    assert mask1.dtype == bool and mask2.dtype == bool\n",
    "    intersection = mask1 & mask2  # Bitwise AND, equivalent to np.logical_and()\n",
    "    return 2*np.sum(intersection)/(np.sum(mask1) + np.sum(mask2))\n",
    "\n",
    "# Initialize dictionaries to store the Dice coefficients for each method\n",
    "dice_scores = {}\n",
    "\n",
    "# Compute the Dice coefficient for each pair of segmented masks and ground truth masks\n",
    "for i in range(len(preprocessed_masks)):\n",
    "    # Binarize the masks\n",
    "    mask_gt_bin = preprocessed_masks[i] > 0\n",
    "    mask_global_bin = segmented_masks_global[i] > 0\n",
    "    mask_adaptive_bin = segmented_masks_adaptive[i] > 0\n",
    "    mask_otsu_bin = segmented_masks_otsu[i] > 0\n",
    "    mask_watershed_bin = segmented_masks_watershed[i] > 0\n",
    "    \n",
    "    # Compute the Dice coefficients\n",
    "    dice_global = dice(mask_gt_bin, mask_global_bin)\n",
    "    dice_adaptive = dice(mask_gt_bin, mask_adaptive_bin)\n",
    "    dice_otsu = dice(mask_gt_bin, mask_otsu_bin)\n",
    "    dice_watershed = dice(mask_gt_bin, mask_watershed_bin)\n",
    "    \n",
    "    # Store the Dice coefficients in the dictionary\n",
    "    dice_scores[f\"Sample {i+1}\"] = {\n",
    "        \"Global\": dice_global,\n",
    "        \"Adaptive\": dice_adaptive,\n",
    "        \"Otsu\": dice_otsu,\n",
    "        \"Watershed\": dice_watershed\n",
    "    }\n",
    "\n",
    "# Display the Dice coefficients\n",
    "dice_df = pd.DataFrame.from_dict(dice_scores, orient='index')\n",
    "\n",
    "# Calculate the mean and standard deviation of the Dice coefficients for each segmentation method\n",
    "mean_scores = dice_df.mean()\n",
    "std_dev = dice_df.std()\n",
    "\n",
    "# Plotting the mean Dice coefficients with error bars for standard deviation\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plotting the mean scores\n",
    "plt.bar(mean_scores.index, mean_scores, yerr=std_dev, capsize=5, color='skyblue', alpha=0.7, label='Mean Dice Coefficient')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Mean Dice Coefficients with Standard Deviation for Different Segmentation Methods')\n",
    "plt.xlabel('Segmentation Method')\n",
    "plt.ylabel('Mean Dice Coefficient')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Showing the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean dice values: \\n\", mean_scores)\n",
    "print(\"Std. dev. dice values: \\n\", std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_discussion'></a>\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Looking at the dataset by eye, it's very clear that on one side, it's quite easy to distinguish between water and non-water. However after looking closer, there are certain challenges such as the changing weather creating clouds around boders or depending on different factors, water simply isn't blue and land is green, brown. Sometimes the water is white because of reflecting clouds or it might be black because it's very deep.\n",
    "\n",
    "Manually creating the segmentation by hand was quite simple with Fiji and I ended creating very similar masks as the ones already in the dataset.\n",
    "\n",
    "Programatically creating the segmentation was of course a bit more challenging. I decided to go with simple, adaptive and Otsu's thresholding first. This already produced some promising results. To go a bit deeper I went on to include the watershed segmentation and put the results for a small sample all into one large graphic.\n",
    "\n",
    "Global Thresholding does a good job when for images with a good contrast, but in other cases procuces bad results. Adaptive Thresholding is generally really good because it detects all the borders, no matter the varying lightnig conditions. Otsu is like global, but better because it's suitable for bimodal images. Watershed works really well with clearly distinguishable borders but fails when the images have lots of noise or small contrasts.\n",
    "\n",
    "I went on and created the masks for a larger part of the dataset and finally used the dice method to compare the results between the different methods. The adaptive method produced the best results at a mean dice coefficient of 0.59, followed by otsu at 0.43, watershed at 0.37 and global at 0.18. It is clear that otsu and wathershed would have scored better if the dataset didn't include borders for some of the satellite images because these algorithms generally work better.\n",
    "\n",
    "It is also worth mentioning that the reference masks included in the dataset, which are also used to create the coefficents, are not perfect. This further falsifies the results.\n",
    "\n",
    "### Issues\n",
    "\n",
    "- The otsu and watershed algorithms couldn't deal well with some images containing black borders around them. I have tried cropping these borders away in the preprocesssing but after investing a lot of time, I didn't manage to create a working function for this issue.\n",
    "\n",
    "- Some images created some problems because they were very distored, resulting in images with zero height in the preprocessing. Also unfortunately I could not get the evaluation to run with all the images because at some point an image would break the program at the binarizing mask step. I have tried to figure this out (see code snippet at the end) but after investing too much time I decided to proceed with only the first 200 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_references'></a>\n",
    "\n",
    "## References\n",
    "\n",
    "- Module Repository by N. Juchler (https://github.com/hirsch-lab/msls-co4-ss24)\n",
    "  - Used for code examples\n",
    "- ChatGPT (https://chatgpt.com/)\n",
    "  - Mainly used for generating basic (repetitive) code snippets and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging of issue that with certain masks I couldn't calculate the dice coefficients\n",
    "for i in range(len(preprocessed_masks)):\n",
    "    # Binarize the masks\n",
    "    mask_gt_bin = preprocessed_masks[i] > 0\n",
    "    mask_otsu_bin = segmented_masks_otsu[i] > 0\n",
    "    mask_adaptive_bin = segmented_masks_adaptive[i] > 0\n",
    "    mask_global_bin = segmented_masks_global[i] > 0\n",
    "    mask_watershed_bin = segmented_masks_watershed[i] > 0\n",
    "    \n",
    "    # print(f\"Shape of ground truth mask: {mask_gt_bin.shape}\")\n",
    "    # print(f\"Shape of Otsu segmented mask: {mask_otsu_bin.shape}\")\n",
    "    # print(f\"Shape of Adaptive segmented mask: {mask_adaptive_bin.shape}\")\n",
    "    # print(f\"Shape of Global segmented mask: {mask_global_bin.shape}\")\n",
    "    # print(f\"Shape of Watershed segmented mask: {mask_watershed_bin.shape}\")\n",
    "    \n",
    "    try:\n",
    "        # Compute the Dice coefficients\n",
    "        dice_otsu = dice(mask_gt_bin, mask_otsu_bin)\n",
    "        dice_adaptive = dice(mask_gt_bin, mask_adaptive_bin)\n",
    "        dice_global = dice(mask_gt_bin, mask_global_bin)\n",
    "        dice_watershed = dice(mask_gt_bin, mask_watershed_bin)\n",
    "        \n",
    "        # Store the Dice coefficients in the dictionary\n",
    "        dice_scores[f\"Sample {i+1}\"] = {\n",
    "            \"Otsu\": dice_otsu,\n",
    "            \"Adaptive\": dice_adaptive,\n",
    "            \"Global\": dice_global,\n",
    "            \"Watershed\": dice_watershed\n",
    "        }\n",
    "    except AssertionError as e:\n",
    "        print(f\"Error occurred for sample {i+1}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-msls-co4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
