{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project work: A mini segmentation challenge\n",
    "\n",
    "Imaging for the Life Sciences  \n",
    "MSLS / CO4: Project work\n",
    "\n",
    "**Student**: $\\Rightarrow$ Mirco Blaser\n",
    "\n",
    "**University**: $\\Rightarrow$ ZHAW\n",
    "\n",
    "**Semester**: $\\Rightarrow$ 4th Semester\n",
    "\n",
    "**Date**: $\\Rightarrow$ June 3rd 2024\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "## Table of contents\n",
    "<!-- Unfortunately, the following does not always work correctly -->\n",
    "* [1. Dataset](#sec_dataset)  \n",
    "* [2. Preprocessing](#sec_preprocessing)  \n",
    "* [3. Manual segmentation](#sec_manual_segmentation)  \n",
    "* [4. Automated segmentation](#sec_automated_segmentation)  \n",
    "* [5. Evaluation](#sec_evaluation)  \n",
    "* [6. Discussion](#sec_discussion)  \n",
    "* [*. Hints](#sec_hints)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prerequisites / Setup\n",
    "\n",
    "$\\Rightarrow$  Special setup instructions, imports and configurations go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "# Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable this line if you want to use the interactive widgets\n",
    "# It requires the ipympl package to be installed.\n",
    "#%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import tools\n",
    "\n",
    "# Number of samples to create for the whole code\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_dataset'></a>\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Title: Satellite Images of Water Bodies\n",
    "\n",
    "Source: [Kaggle](https://www.kaggle.com/datasets/franciscoescobar/satellite-images-of-water-bodies)\n",
    "\n",
    "Description: A collection of water bodies images captured by the Sentinel-2 Satellite. Each image comes with a black and white mask where white represents water and black represents something else but water. The masks were generated by calculating the NWDI (Normalized Water Difference Index) which is frequently used to detect and measure vegetation in satellite images, but a greater threshold was used to detect water bodies.\n",
    "\n",
    "- **Images**: These are the raw satellite images.\n",
    "- **Masks**: These are the binary masks where water bodies are labeled.\n",
    "\n",
    "Below are examples of the images and their corresponding masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the directories containing images and masks\n",
    "images_path = './data/Images'\n",
    "masks_path = './data/Masks'\n",
    "\n",
    "# Function to load images and masks\n",
    "def load_images_masks(image_dir, mask_dir, num_samples):\n",
    "    image_files = sorted(os.listdir(image_dir))[:num_samples]\n",
    "    mask_files = sorted(os.listdir(mask_dir))[:num_samples]\n",
    "    \n",
    "    images = [Image.open(os.path.join(image_dir, file)) for file in image_files]\n",
    "    masks = [Image.open(os.path.join(mask_dir, file)) for file in mask_files]\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "# Load the first num_samples images and masks\n",
    "images, masks = load_images_masks(images_path, masks_path, num_samples)\n",
    "\n",
    "# Display the images and masks\n",
    "fig, axs = plt.subplots(num_samples, 2, figsize=(10, num_samples*5))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axs[i, 0].imshow(images[i])\n",
    "    axs[i, 0].set_title(f'Image {i+1}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Mask {i+1}')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_preprocessing'></a>\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "1. **Resizing**: Standardized the image sizes to 256x256 pixels.\n",
    "2. **Normalization**: Adjusted the pixel values to the range [0, 1].\n",
    "3. **Contrast Enhancement**: Applied histogram equalization to enhance the contrast of the images.\n",
    "\n",
    "Below are the examples of the preprocessed images and their corresponding masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image, ismask):\n",
    "    \"\"\"\n",
    "    Preprocess the input image: resize while maintaining aspect ratio,\n",
    "    convert to grayscale if it's not a mask.\n",
    "    \n",
    "    Args:\n",
    "    - image (PIL.Image): The input image to preprocess.\n",
    "    - ismask (bool): Flag to indicate if the image is a mask.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: The preprocessed image.\n",
    "    \"\"\"\n",
    "    target_width = 256\n",
    "    \n",
    "    # Calculate the target height to maintain the original aspect ratio\n",
    "    width, height = image.size\n",
    "    target_height = int(height * (target_width / width))\n",
    "    \n",
    "    # Resize the image while maintaining aspect ratio\n",
    "    image_resized = image.resize((target_width, target_height), PIL.Image.LANCZOS)\n",
    "    \n",
    "    if not ismask:\n",
    "        \n",
    "        # Convert the image to a numpy array and then to grayscale directly\n",
    "        image_array = np.array(image_resized)\n",
    "        image_grayscale = cv.cvtColor(image_array, cv.COLOR_BGR2GRAY)\n",
    "        image_enhanced = image_grayscale\n",
    "    else:\n",
    "        image_enhanced = np.array(image_resized.convert('L'))\n",
    "    \n",
    "    return image_enhanced\n",
    "\n",
    "# Ensure num_samples does not exceed the length of images or masks\n",
    "num_samples = min(len(images), len(masks))\n",
    "\n",
    "# Preprocess the first num_samples images and masks\n",
    "preprocessed_images = [preprocess_image(images[i], ismask=False) for i in range(num_samples)]\n",
    "preprocessed_masks = [preprocess_image(masks[i], ismask=True) for i in range(num_samples)]\n",
    "\n",
    "# Display the preprocessed images and masks\n",
    "fig, axs = plt.subplots(num_samples, 2, figsize=(10, num_samples*5))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axs[i, 0].imshow(preprocessed_images[i], cmap='gray')\n",
    "    axs[i, 0].set_title(f'Preprocessed Image {i+1}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(preprocessed_masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Preprocessed Mask {i+1}')\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='sec_manual_segmentation'></a>\n",
    "\n",
    "## Manual segmentation\n",
    "\n",
    "For the manual segmentation, the Fiji (ImageJ) software was used. Fiji is an open-source image processing package that is widely used in the life sciences for its powerful and user-friendly tools.\n",
    "\n",
    "### Steps for Manual Segmentation in Fiji:\n",
    "\n",
    "1. **Open Image**: Load the image into Fiji by going to `File > Open...` and selecting the image file.\n",
    "2. **Select the Region of Interest**: Use the Polygon selection tool to carefully outline the water body in the image.\n",
    "3. **Create a Mask**: Once the water body is selected, go to Edit > Selection > Create Mask. This creates a binary mask where the selected region is white, and the rest is black.\n",
    "5. **Save Mask**: Save the resulting mask by going to `File > Save As > PNG...`.\n",
    "\n",
    "The following code displays the original images, the original masks, and the manually segmented masks for the selected images (100, 170, and 708)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the directories containing images and masks\n",
    "images_path = './data/Images/'\n",
    "masks_path = './data/Masks/'\n",
    "manual_masks_path = './manual/'\n",
    "\n",
    "# List of specific image indices to load\n",
    "image_indices = [100, 170, 708]\n",
    "\n",
    "# Function to load specific images and masks\n",
    "def load_specific_images_masks(image_dir, mask_dir, manual_mask_dir, indices):\n",
    "    images = []\n",
    "    masks = []\n",
    "    manual_masks = []\n",
    "    for index in indices:\n",
    "        image_file = f'water_body_{index}.jpg'\n",
    "        mask_file = f'water_body_{index}.jpg'\n",
    "        manual_mask_file = f'water_body_{index}.png'\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        manual_mask_path = os.path.join(manual_mask_dir, manual_mask_file)\n",
    "        images.append(Image.open(image_path))\n",
    "        masks.append(Image.open(mask_path))\n",
    "        manual_masks.append(Image.open(manual_mask_path))\n",
    "    \n",
    "    return images, masks, manual_masks\n",
    "\n",
    "# Load the specific images and masks\n",
    "images, masks, manual_masks = load_specific_images_masks(images_path, masks_path, manual_masks_path, image_indices)\n",
    "\n",
    "# Display the images and masks\n",
    "fig, axs = plt.subplots(len(images), 3, figsize=(10, 5 * len(images)))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    axs[i, 0].imshow(images[i])\n",
    "    axs[i, 0].set_title(f'Image {image_indices[i]}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Original Mask {image_indices[i]}')\n",
    "    axs[i, 1].axis('off')\n",
    "    \n",
    "    axs[i, 2].imshow(manual_masks[i], cmap='gray')\n",
    "    axs[i, 2].set_title(f'Manually segmented Mask {image_indices[i]}')\n",
    "    axs[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_automated_segmentation'></a>\n",
    "\n",
    "## Automated segmentation\n",
    "\n",
    "$\\Rightarrow$ Describe how to segment the image in Python\n",
    "\n",
    "\n",
    "### Goals:\n",
    "* The segmentation must be performed in Python.\n",
    "* Using an external library or tool (e.g. OpenCV) is permitted.\n",
    "* Implement a function `segment(image, ...)` takes an image as input and creates a segmentation mask for the structure of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the segmentation function\n",
    "def segment(image, method='global'):\n",
    "    \"\"\"\n",
    "    Segment the image using the specified method.\n",
    "    \n",
    "    Args:\n",
    "    - image (numpy.ndarray): The input image to segment.\n",
    "    - method (str): The thresholding method to use ('global', 'adaptive', 'otsu', 'watershed').\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: The segmentation mask.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check the number of channels in the image\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        # Convert the image to grayscale if it has 3 channels\n",
    "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        # Image is already in grayscale\n",
    "        gray = image\n",
    "    \n",
    "    if method == 'global':\n",
    "        # Apply global thresholding\n",
    "        _, mask = cv.threshold(gray, 127, 255, cv.THRESH_BINARY)\n",
    "    elif method == 'adaptive':\n",
    "        # Apply adaptive thresholding\n",
    "        mask = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2)\n",
    "    elif method == 'otsu':\n",
    "        # Apply Otsu's thresholding\n",
    "        _, mask = cv.threshold(gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    elif method == 'watershed':\n",
    "        # Apply watershed segmentation\n",
    "        markers, img = segment_watershed(image)\n",
    "        # Create a binary mask where the segmented regions are white\n",
    "        mask = np.zeros_like(gray)\n",
    "        mask[markers > 1] = 255  # We assume the labels greater than 1 correspond to foreground regions\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def segment_watershed(img):\n",
    "    img = cv.GaussianBlur(img, (5, 5), 0)\n",
    "    img_blur = cv.medianBlur(img, 5)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    if len(img_blur.shape) == 3 and img_blur.shape[2] == 3:\n",
    "        gray = cv.cvtColor(img_blur, cv.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img_blur\n",
    "    \n",
    "    ret, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "    # Noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=9)\n",
    "\n",
    "    # Sure background area\n",
    "    sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
    "    thr = 18\n",
    "    ret, sure_fg = cv.threshold(dist_transform, thr, 255, 0)\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    # Ensure the image is in color\n",
    "    if len(img.shape) == 2 or img.shape[2] != 3:\n",
    "        img = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    markers = cv.watershed(img, markers)\n",
    "    img[markers == -1] = [255, 0, 0]\n",
    "\n",
    "    return markers, img\n",
    "\n",
    "# Segment the preprocessed images using different methods\n",
    "segmented_masks_otsu = [segment(image, method='otsu') for image in preprocessed_images]\n",
    "segmented_masks_adaptive = [segment(image, method='adaptive') for image in preprocessed_images]\n",
    "segmented_masks_global = [segment(image, method='global') for image in preprocessed_images]\n",
    "segmented_masks_watershed = [segment(image, method='watershed') for image in preprocessed_images]\n",
    "\n",
    "# Display the results\n",
    "fig, axs = plt.subplots(num_samples, 6, figsize=(20, num_samples * 5))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axs[i, 0].imshow(preprocessed_images[i], cmap='gray')\n",
    "    axs[i, 0].set_title(f'Preprocessed Image {i+1}')\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(preprocessed_masks[i], cmap='gray')\n",
    "    axs[i, 1].set_title(f'Preprocessed Mask {i+1}')\n",
    "    axs[i, 1].axis('off')\n",
    "    \n",
    "    axs[i, 2].imshow(segmented_masks_global[i], cmap='gray')\n",
    "    axs[i, 2].set_title(f'Global Threshold {i+1}')\n",
    "    axs[i, 2].axis('off')\n",
    "    \n",
    "    axs[i, 3].imshow(segmented_masks_adaptive[i], cmap='gray')\n",
    "    axs[i, 3].set_title(f'Adaptive Threshold {i+1}')\n",
    "    axs[i, 3].axis('off')\n",
    "    \n",
    "    axs[i, 4].imshow(segmented_masks_otsu[i], cmap='gray')\n",
    "    axs[i, 4].set_title(f'Otsu Threshold {i+1}')\n",
    "    axs[i, 4].axis('off')\n",
    "    \n",
    "    axs[i, 5].imshow(segmented_masks_watershed[i], cmap='gray')\n",
    "    axs[i, 5].set_title(f'Watershed {i+1}')\n",
    "    axs[i, 5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_evaluation'></a>\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "$\\Rightarrow$ Describe the evaluation of your results\n",
    "\n",
    "\n",
    "### Goals:\n",
    "* Choose an evaluation method that can compare two binary segmentation masks and computes a numeric score that describes how well these masks match (use for example the Dice score)\n",
    "* Hint: specify a function `evaluate(mask1, mask2)` that computes the evaluation score(s)\n",
    "* Compute mean and standard deviation of the scores of the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_discussion'></a>\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Borders\n",
    "Unfortunately, Otsu and Watershed can't deal well with some images containing black borders around them. I have tried cropping these borders away in the preprocesssing but after investing a lot of time, I didn't manage to create a workable function for this issue.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='sec_references'></a>\n",
    "\n",
    "## References\n",
    "\n",
    "$\\Rightarrow$ Add here references as URLs.\n",
    "\n",
    "Also declare the usage of **generative AI** here!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways how to overlay an image with the mask. Here is one option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce a (3-channel) color image\n",
    "path_image = \"../data/images/neurons-cultured.jpg\"\n",
    "image = cv.imread(path_image, cv.IMREAD_COLOR)\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# Mask image\n",
    "path_mask = \"../data/images/neurons-cultured-mask.png\"\n",
    "mask = cv.imread(path_mask, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Create overlay (RGB)\n",
    "overlay_color = [255, 0, 0]\n",
    "overlay_alpha = 0.3\n",
    "overlay = image.copy()\n",
    "overlay[mask > 0] = overlay_color\n",
    "overlay = cv.addWeighted(image, 1 - overlay_alpha, overlay, overlay_alpha, 0)\n",
    "\n",
    "# Display the images next to each other using a convenience function\n",
    "tools.show_image_chain((image, overlay), titles=(\"Input\", \"Overlay\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also create contours around the mask and display them\n",
    "overlay_color = [255, 255, 0]\n",
    "line_width = 1\n",
    "contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "image_contours = image.copy()\n",
    "cv.drawContours(image_contours, contours, -1, overlay_color, line_width)\n",
    "tools.show_image_chain((image, image_contours), titles=(\"Input\", \"Contours\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advanced example: We can colorize the different contours with different colors.\n",
    "\n",
    "Strategy:\n",
    "- Use connected components to label the different regions using integers \n",
    "(every region has a different label)\n",
    "- Assign a different color to different labels by encoding the label in \n",
    "the hue channel (HSV color space!)\n",
    "- Extract contours from the mask (must be a binary image)\n",
    "- Merge draw the contours with the colorized labels onto the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will contain the result\n",
    "image_contours = image.copy()\n",
    "\n",
    "# Compute the \"connected components\" (= separate objects in the mask)\n",
    "n_labels, labels = cv.connectedComponents(mask)\n",
    "\n",
    "# Assign a different color to each label in the hue channel (HSV color space)\n",
    "hue = np.uint8(150*labels/np.max(labels))\n",
    "blank = 255*np.ones_like(hue)\n",
    "labels = cv.merge([hue, blank, blank])\n",
    "\n",
    "# Convert from HSV color space to RGB\n",
    "labels = cv.cvtColor(labels, cv.COLOR_HSV2RGB)\n",
    "# Set the background label (labels==0) to black\n",
    "labels[labels==0] = 0\n",
    "\n",
    "#Â Create a mask of the contours\n",
    "line_width = 1\n",
    "contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "mask_contours = cv.drawContours(np.zeros_like(mask), contours, -1, 255, line_width)\n",
    "\n",
    "# Assign the colored labels only along the contours\n",
    "image_contours[mask_contours>0] = labels[mask_contours>0]\n",
    "\n",
    "# Display the result\n",
    "tools.show_image_chain((image, image_contours), titles=(\"Input\", \"Labeled contours\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to convert a Jupyter notebook into a PDF:\n",
    "\n",
    "- Don't forget to save this notebook before converting!\n",
    "- Install nbconvert: `pip install nbconvert`\n",
    "- Convert the notebook into a HTML file: `jupyter nbconvert --to html main.ipynb`  \n",
    "  The file will be saved in the same folder as this Jupyter notebook\n",
    "- Open the HTML in a browser and print (or save) it as a PDF\n",
    "- Recommendation: If you use the Opera browser, you can save the HTML as single-page PDF. This looks the best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you save this notebook, otherwise the HTML \n",
    "# output will not contain the latest version!!\n",
    "\n",
    "# Make sure you have nbcovnert installed\n",
    "!pip install nbconvert --quiet\n",
    "# Save the notebook as HTML\n",
    "!jupyter nbconvert --to html main.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-msls-co4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
